{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyMbL+QhCUVYZpePHqB5J8kr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install tensorflow==2.15.1"],"metadata":{"id":"9d8DHfMLCrZi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","print(tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ElFkA7UPCuCq","executionInfo":{"status":"ok","timestamp":1723943772336,"user_tz":-540,"elapsed":3828,"user":{"displayName":"김하연","userId":"03660680607316361176"}},"outputId":"8db874c7-42da-4d32-82f2-545a82c3ac60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.15.1\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"upEBywmxizJX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723943904564,"user_tz":-540,"elapsed":91471,"user":{"displayName":"김하연","userId":"03660680607316361176"}},"outputId":"498fb598-888d-4ed9-ad71-d96753157d9d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A_zVigS1jVhV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723943909501,"user_tz":-540,"elapsed":2208,"user":{"displayName":"김하연","userId":"03660680607316361176"}},"outputId":"494116a8-7680-4945-dce7-b7b594964895"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From <ipython-input-4-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.config.list_physical_devices('GPU')` instead.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}],"source":["tf.test.is_gpu_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9oCTREgQjYRY"},"outputs":[],"source":["# 이미지 처리\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G8uy0SqPukYt"},"outputs":[],"source":["# json 파일 처리\n","import json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QxBD9_ZdjZ7y"},"outputs":[],"source":["# 파일 존재 여부 확인용\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pPGmA2wBNrNo"},"outputs":[],"source":["# Train 데이터에서 훈련용 데이터와 검증용 데이터 분리\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WWHPFeyujbH2"},"outputs":[],"source":["# 모델\n","from tensorflow import keras"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rbGlaphjYh0v"},"outputs":[],"source":["# 랜덤숫자 생성\n","import random"]},{"cell_type":"markdown","metadata":{"id":"25I-lCVAjnnC"},"source":["# 변수 목록"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p9ACh1bzqP7g"},"outputs":[],"source":["os.chdir('/content/drive/MyDrive/[perst]데이터셋/MachineLearningProject/02_Fashion Type Classification Model')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"imgAJ3qBjtB6"},"outputs":[],"source":["# train_dir_name = \"./Dataset/Musinsa_Dataset/Train-Test_0515/Female/Train/\"\n","# test_dir_name = \"./Dataset/Musinsa_Dataset/Train-Test_0515/Female/Test/\"\n","\n","train_dir_name = \"./Dataset/Musinsa_Dataset/Train-Test_0617/Female/Train/\"\n","test_dir_name = \"./Dataset/Musinsa_Dataset/Train-Test_0617/Female/Test/\"\n","\n","img_width = 200\n","img_height = 200\n","\n","model_dir_name = './Model/' # 학습 모델이 저장될 디렉토리명"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AsUPtXwBA_HG"},"outputs":[],"source":["label_name = ['Girlish', 'Gofcore', 'Golf', 'Retro', 'Romantic', 'Business-Casual', 'Street', 'Sporty', 'Chic', 'Amekaji', 'Casual']"]},{"cell_type":"code","source":["season_name = ['Spring', 'Summer', 'Autumn', 'Winter']"],"metadata":{"id":"8CBMtjujLUlj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JuBHl9sOqpH6"},"source":["# Train-Test 데이터 불러오기"]},{"cell_type":"code","source":["# print(len(os.listdir(train_dir_name + \"Image\")))\n","# 19585"],"metadata":{"id":"hs-x83I59bRf"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T4egSROIqr6y","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d398fd7f-4640-4216-bc26-8e16ef776960"},"outputs":[{"output_type":"stream","name":"stdout","text":["500개 파일 읽기 완료\n","1000개 파일 읽기 완료\n","1500개 파일 읽기 완료\n","2000개 파일 읽기 완료\n","2500개 파일 읽기 완료\n","3000개 파일 읽기 완료\n","3500개 파일 읽기 완료\n","4000개 파일 읽기 완료\n","4500개 파일 읽기 완료\n","5000개 파일 읽기 완료\n","5500개 파일 읽기 완료\n"]}],"source":["x_train_ori = []\n","y_train_ori = []\n","\n","for i in range(0, 19586):\n","    img_path = train_dir_name + \"Image/\" + str(i) + \".jpg\"\n","    label_path = train_dir_name + \"Json/\" + str(i) + \".json\"\n","\n","    if not os.path.isfile(img_path):\n","        continue\n","    if not os.path.isfile(label_path):\n","        continue\n","\n","    # json 파일 로드\n","    with open(label_path, \"r\") as loadfile:\n","      label_file = json.load(loadfile)\n","    if label_file is None:\n","        print(str(i) + \".json File Load Failed!!\")\n","        break\n","\n","\n","    # 이미지 파일 로드\n","    img_file_color = cv2.imread(img_path)\n","    if img_file_color is None:\n","        print(str(i) + \".jpg File Load Failed!!\")\n","        break\n","\n","    # 이미지 파일을 흑백으로 변환\n","    # img_file_gray = cv2.cvtColor(img_file_color, cv2.COLOR_BGR2GRAY)\n","\n","\n","    x_train_ori.append(img_file_color)\n","    y_train_ori.append(label_file)\n","\n","\n","    if len(y_train_ori)%500 == 0: # 진행도 확인용\n","        print(str(len(y_train_ori)) + \"개 파일 읽기 완료\")\n","\n","\n","print(\"Complete\")\n"]},{"cell_type":"code","source":["# print(len(os.listdir(test_dir_name + \"Image\")))\n","# 4900"],"metadata":{"id":"lSWJQM4R9rIX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"reb3jK-hFQyy"},"outputs":[],"source":["x_test = []\n","y_test_ori = []\n","\n","for i in range(0, 4901):\n","    img_path = test_dir_name + \"Image/\" + str(i) + \".jpg\"\n","    label_path = test_dir_name + \"Json/\" + str(i) + \".json\"\n","\n","    if not os.path.isfile(img_path):\n","        continue\n","    if not os.path.isfile(label_path):\n","        continue\n","\n","    # json 파일 로드\n","    with open(label_path, \"r\") as loadfile:\n","      label_file = json.load(loadfile)\n","    if label_file is None:\n","        print(str(i) + \".json File Load Failed!!\")\n","        break\n","\n","\n","    # 이미지 파일 로드\n","    img_file_color = cv2.imread(img_path)\n","    if img_file_color is None:\n","        print(str(i) + \".jpg File Load Failed!!\")\n","        break\n","\n","    # 이미지 파일을 흑백으로 변환\n","    # img_file_gray = cv2.cvtColor(img_file_color, cv2.COLOR_BGR2GRAY)\n","\n","\n","    x_test.append(img_file_color)\n","    y_test_ori.append(label_file)\n","\n","\n","    if len(y_test_ori)%500 == 0: # 진행도 확인용\n","        print(str(len(y_test_ori)) + \"개 파일 읽기 완료\")\n","\n","\n","print(\"Complete\")\n"]},{"cell_type":"markdown","source":["# 이미지 확인"],"metadata":{"id":"NhXhiBMKb7DS"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 5))\n","\n","plt.subplot(1, 2, 1)\n","plt.imshow(x_train_ori[0])\n","plt.title(\"Train X Image\")\n","\n","plt.subplot(1, 2, 2)\n","plt.imshow(x_test[0])\n","plt.title(\"Test X Image\")\n","\n","plt.show()"],"metadata":{"id":"V9kw8UKAb6Lx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jCRYJUiFWmE3"},"source":["# 학습을 위해 X,Y데이터 형식 변경"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WImkUXINWmE4"},"outputs":[],"source":["x_train_ori = np.array(x_train_ori)\n","x_train_ori.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x9aZAJ4pWxzq"},"outputs":[],"source":["x_test = np.array(x_test)\n","x_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eEYJk3SjWmE5"},"outputs":[],"source":["y_train = []\n","season_train = []\n","\n","for item in y_train_ori:\n","  label_num = label_name.index(item['Labeling'])\n","\n","  y_train.append(label_num)\n","  season_train.append(item[\"Season\"])\n","\n","print(y_train[0])\n","print(season_train[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ecg7qwAWmE5"},"outputs":[],"source":["y_test = []\n","season_test = []\n","\n","for item in y_test_ori:\n","  label_num = label_name.index(item['Labeling'])\n","\n","  y_test.append(label_num)\n","  season_test.append(item[\"Season\"])\n","\n","print(y_test[0])\n","print(season_test[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tyfm-syNX7WS"},"outputs":[],"source":["y_train = np.array(y_train)\n","y_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sSUi0g3UZ0PT"},"outputs":[],"source":["y_train = y_train.astype('uint8')\n","y_train.dtype"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iHojYLxyaIMx"},"outputs":[],"source":["y_test = np.array(y_test)\n","y_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z5YIio5OaaU1"},"outputs":[],"source":["y_test = y_test.astype('uint8')\n","y_test.dtype"]},{"cell_type":"markdown","source":["# 계절 정보 통계"],"metadata":{"id":"Qb1QyBea95EG"}},{"cell_type":"markdown","source":["## Train 계절 통계"],"metadata":{"id":"Dh-p3Hnz-AzE"}},{"cell_type":"code","source":["season_count = []\n","\n","season_count.append(season_train.count('Spring'))\n","season_count.append(season_train.count('Summer'))\n","season_count.append(season_train.count('Autumn'))\n","season_count.append(season_train.count('Winter'))\n","season_count.append(season_train.count('None'))\n","\n","print(season_count)"],"metadata":{"id":"BxMG4He994Ad"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["season_str = ['Spring', 'Summer', 'Autumn', 'Winter', 'None']\n","\n","plt.figure(figsize=(10, 5))\n","\n","plt.subplot(1, 2, 1)\n","barplot = plt.bar(season_str, season_count)\n","plt.xticks(rotation=90)\n","\n","for i, j in enumerate(barplot) :\n","    plt.text(i, j.get_height() + 0.5, season_count[i], ha = 'center')\n","\n","plt.subplot(1, 2, 2)\n","plt.pie(season_count, startangle=90, counterclock=False)\n","plt.legend(season_str, loc=(1.0, 0.3))\n","\n","plt.title(\"Season Count\")\n","plt.show()"],"metadata":{"id":"KUlcH-jR_WwB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Test 계절 통계"],"metadata":{"id":"tYpzioIe-CX_"}},{"cell_type":"code","source":["season_count = []\n","\n","season_count.append(season_test.count('Spring'))\n","season_count.append(season_test.count('Summer'))\n","season_count.append(season_test.count('Autumn'))\n","season_count.append(season_test.count('Winter'))\n","season_count.append(season_test.count('None'))\n","\n","print(season_count)"],"metadata":{"id":"Ph3XwbqW_bPP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["season_str = ['Spring', 'Summer', 'Autumn', 'Winter', 'None']\n","\n","plt.figure(figsize=(10, 5))\n","\n","plt.subplot(1, 2, 1)\n","barplot = plt.bar(season_str, season_count)\n","plt.xticks(rotation=90)\n","\n","for i, j in enumerate(barplot) :\n","    plt.text(i, j.get_height() + 0.5, season_count[i], ha = 'center')\n","\n","plt.subplot(1, 2, 2)\n","plt.pie(season_count, startangle=90, counterclock=False)\n","plt.legend(season_str, loc=(1.0, 0.3))\n","\n","plt.title(\"Season Count\")\n","plt.show()"],"metadata":{"id":"mcWtDJRJ_bPZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h1Y10ZH_N432"},"source":["# Train 데이터에서 Validation 데이터 분리"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3GJEySXzN9oA"},"outputs":[],"source":["y_train_all = y_train[:]\n","\n","x_train = []\n","y_train = []\n","x_val = []\n","y_val = []\n","\n","x_train, x_val, y_train, y_val = train_test_split(x_train_ori, y_train_all, test_size=0.25, stratify=y_train_all)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k1dO0yZdOudK"},"outputs":[],"source":["x_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XaaDmutqOv1k"},"outputs":[],"source":["y_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8gycPnXqOxT2"},"outputs":[],"source":["x_val.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"es3dOZeTO0RT"},"outputs":[],"source":["y_val.shape"]},{"cell_type":"markdown","metadata":{"id":"5D9mbUFXruGR"},"source":["# 학습 데이터 통계"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S0pluhix8NHq"},"outputs":[],"source":["# 라벨 개수 카운트\n","label_count = {}\n","\n","for item in y_train:\n","    label = label_name[item]\n","    if label not in label_count: # 해당 키가 없을 경우\n","        label_count[label] = 1\n","    else:\n","        label_count[label] = label_count[label]+1\n","\n","\n","# 내림차순 정렬\n","label_count = sorted(label_count.items(), key= lambda item:item[1], reverse=True)\n","\n","label_count_labels = []\n","label_count_values = []\n","\n","for item in label_count:\n","    label_count_labels.append(item[0])\n","    label_count_values.append(item[1])\n","\n","\n","# 파이 차트를 위한 라벨링 생성\n","total = np.sum(label_count_values)\n","label_count_labels_ratio = []\n","\n","for i in range(0, len(label_count_labels)):\n","    ratio = (label_count_values[i]/total) * 100\n","\n","    new_label = label_count_labels[i] + (' %.1f%%' % ratio)\n","    label_count_labels_ratio.append(new_label)\n","\n","\n","# 차트 그리기\n","plt.figure(figsize=(10, 5))\n","\n","plt.subplot(1, 2, 1)\n","barplot = plt.bar(label_count_labels, label_count_values)\n","plt.xticks(rotation=90)\n","\n","for i, j in enumerate(barplot) :\n","    plt.text(i, j.get_height() + 0.5, label_count_values[i], ha = 'center')\n","\n","plt.subplot(1, 2, 2)\n","plt.pie(label_count_values, startangle=90, counterclock=False)\n","plt.legend(label_count_labels_ratio, loc=(1.0, 0.3))\n","\n","plt.title(\"Train Data Labeling Count\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GQHJU3F76DeI"},"outputs":[],"source":["# 라벨 개수 카운트\n","label_count = {}\n","\n","for item in y_val:\n","  label = label_name[item]\\\n","  if label not in label_count: # 해당 키가 없을 경우\n","    label_count[label] = 1\n","  else:\n","    label_count[label] = label_count[label]+1\n","\n","\n","# 내림차순 정렬\n","label_count = sorted(label_count.items(), key= lambda item:item[1], reverse=True)\n","\n","label_count_labels = []\n","label_count_values = []\n","\n","for item in label_count:\n","    label_count_labels.append(item[0])\n","    label_count_values.append(item[1])\n","\n","\n","# 파이 차트를 위한 라벨링 생성\n","total = np.sum(label_count_values)\n","label_count_labels_ratio = []\n","\n","for i in range(0, len(label_count_labels)):\n","    ratio = (label_count_values[i]/total) * 100\n","\n","    new_label = label_count_labels[i] + (' %.1f%%' % ratio)\n","    label_count_labels_ratio.append(new_label)\n","\n","\n","# 차트 그리기\n","plt.figure(figsize=(10, 5))\n","\n","plt.subplot(1, 2, 1)\n","barplot = plt.bar(label_count_labels, label_count_values)\n","plt.xticks(rotation=90)\n","\n","for i, j in enumerate(barplot) :\n","    plt.text(i, j.get_height() + 0.5, label_count_values[i], ha = 'center')\n","\n","plt.subplot(1, 2, 2)\n","plt.pie(label_count_values, startangle=90, counterclock=False)\n","plt.legend(label_count_labels_ratio, loc=(1.0, 0.3))\n","\n","plt.title(\"Validation Data Labeling Count\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iMYtxo8yFp4p"},"outputs":[],"source":["# 라벨 개수 카운트\n","label_count = {}\n","\n","for item in y_test:\n","  label = label_name[item]\n","  if label not in label_count: # 해당 키가 없을 경우\n","    label_count[label] = 1\n","  else:\n","    label_count[label] = label_count[label]+1\n","\n","\n","# 내림차순 정렬\n","label_count = sorted(label_count.items(), key= lambda item:item[1], reverse=True)\n","\n","label_count_labels = []\n","label_count_values = []\n","\n","for item in label_count:\n","    label_count_labels.append(item[0])\n","    label_count_values.append(item[1])\n","\n","\n","# 파이 차트를 위한 라벨링 생성\n","total = np.sum(label_count_values)\n","label_count_labels_ratio = []\n","\n","for i in range(0, len(label_count_labels)):\n","    ratio = (label_count_values[i]/total) * 100\n","\n","    new_label = label_count_labels[i] + (' %.1f%%' % ratio)\n","    label_count_labels_ratio.append(new_label)\n","\n","\n","# 차트 그리기\n","plt.figure(figsize=(10, 5))\n","\n","plt.subplot(1, 2, 1)\n","barplot = plt.bar(label_count_labels, label_count_values)\n","plt.xticks(rotation=90)\n","\n","for i, j in enumerate(barplot) :\n","    plt.text(i, j.get_height() + 0.5, label_count_values[i], ha = 'center')\n","\n","plt.subplot(1, 2, 2)\n","plt.pie(label_count_values, startangle=90, counterclock=False)\n","plt.legend(label_count_labels_ratio, loc=(1.0, 0.3))\n","\n","plt.title(\"Test Data Labeling Count\")\n","plt.show()"]},{"cell_type":"markdown","source":["# Train 데이터 어그멘테이션"],"metadata":{"id":"QdwJpyVjq8zQ"}},{"cell_type":"code","source":["# 혹시 모르니 백업해두기\n","ori_x_train = x_train[:]\n","ori_y_train = y_train[:]\n","\n","print(ori_x_train.shape)\n","print(ori_y_train.shape)"],"metadata":{"id":"UTYV7CUIvJLr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Before length\")\n","print(x_train.shape)\n","print(y_train.shape)\n","print()\n","\n","# 변형을 위해 리스트로 변환\n","x_train = list(x_train)\n","y_train = list(y_train)\n","\n","ori_len = len(x_train) # 계속 길이가 추가될 테니까 미리 계산\n","for i in range(0, ori_len):\n","  # 진행도 체크\n","  if (i+1)%1000 == 0:\n","    print(str(i+1) + \"개 Train 데이터 적용 완료\")\n","\n","  # 90도 회전\n","  rotate_90 = cv2.rotate(x_train[i], cv2.ROTATE_90_CLOCKWISE)\n","  x_train.append(rotate_90)\n","  y_train.append(y_train[i])\n","\n","  # 180도 회전\n","  rotate_180 = cv2.rotate(x_train[i], cv2.ROTATE_180)\n","  x_train.append(rotate_180)\n","  y_train.append(y_train[i])\n","\n","  # 270도 회전\n","  rotate_270 = cv2.rotate(x_train[i], cv2.ROTATE_90_COUNTERCLOCKWISE)\n","  x_train.append(rotate_270)\n","  y_train.append(y_train[i])\n","\n","\n","# 학습을 위해 다시 ndarray 형태로 변환\n","x_train = np.array(x_train)\n","y_train = np.array(y_train)\n","\n","print()\n","print(\"Complete\")\n","print(\"After length\")\n","print(x_train.shape)\n","print(y_train.shape)"],"metadata":{"id":"BafwcVwPq6xX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 어그멘테이션 확인"],"metadata":{"id":"HTno35pvt_lL"}},{"cell_type":"code","source":["rand_num = random.randint(0, ori_len)\n","print(\"Random Number : \", rand_num)\n","\n","plt.figure(figsize=(20, 5))\n","\n","plt.subplot(1, 4, 1)\n","plt.imshow(x_train[rand_num])\n","plt.title(\"Original Image\")\n","\n","plt.subplot(1, 4, 2)\n","plt.imshow(x_train[ori_len + (rand_num*3)])\n","plt.title(\"Rotate 90\")\n","\n","plt.subplot(1, 4, 3)\n","plt.imshow(x_train[ori_len + (rand_num*3) + 1])\n","plt.title(\"Rotate 180\")\n","\n","plt.subplot(1, 4, 4)\n","plt.imshow(x_train[ori_len + (rand_num*3) + 2])\n","plt.title(\"Rotate 270\")\n","\n","plt.show()"],"metadata":{"id":"_EoJGNoGuBbY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bitN4gZz8UBU"},"source":["# 모델 생성"]},{"cell_type":"markdown","metadata":{"id":"gXjsn0E0ZjE7"},"source":["## 케라스 기본 모델들"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_D8XKQq-WoL_"},"outputs":[],"source":["fashion_model = keras.applications.VGG16(include_top=True,\n","                                         weights=None,\n","                                         input_tensor=None,\n","                                         input_shape=(img_height, img_width, 3),\n","                                         pooling='max',\n","                                         classes=11,\n","                                         classifier_activation='softmax')"]},{"cell_type":"code","source":["fashion_model = keras.applications.VGG19(include_top=True,\n","                                         weights=None,\n","                                         input_tensor=None,\n","                                         input_shape=(img_height, img_width, 3),\n","                                         pooling='max',\n","                                         classes=11,\n","                                         classifier_activation=\"softmax\")"],"metadata":{"id":"P_yXZCdzQo_v"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aqhW__SPaNUy"},"outputs":[],"source":["fashion_model = keras.applications.ResNet50(include_top=True,\n","                                            weights=None,\n","                                            input_tensor=None,\n","                                            input_shape=(img_height, img_width, 3),\n","                                            pooling='max',\n","                                            classes=11)"]},{"cell_type":"code","source":["fashion_model = keras.applications.ResNet101(include_top=True,\n","                                             weights=None,\n","                                             input_tensor=None,\n","                                             input_shape=(img_height, img_width, 3),\n","                                             pooling='max',\n","                                             classes=11,\n","                                             classifier_activation=\"softmax\")"],"metadata":{"id":"4Q3_WhLok9B1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fashion_model = keras.applications.ResNet152(include_top=True,\n","                                             weights=None,\n","                                             input_tensor=None,\n","                                             input_shape=(img_height, img_width, 3),\n","                                             pooling='max',\n","                                             classes=11,\n","                                             classifier_activation=\"softmax\")"],"metadata":{"id":"t1x83F4LUNml"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fashion_model = keras.applications.ResNet50V2(include_top=True,\n","                                              weights=None,\n","                                              input_tensor=None,\n","                                              input_shape=(img_height, img_width, 3),\n","                                              pooling='max',\n","                                              classes=11,\n","                                              classifier_activation=\"softmax\")"],"metadata":{"id":"XHKLECOYZW5Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fashion_model = keras.applications.ResNet101V2(include_top=True,\n","                                               weights=None,\n","                                               input_tensor=None,\n","                                               input_shape=(img_height, img_width, 3),\n","                                               pooling='max',\n","                                               classes=11,\n","                                               classifier_activation=\"softmax\")"],"metadata":{"id":"ftNHN84EmDiF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fashion_model = keras.applications.ResNet152V2(include_top=True,\n","                                               weights=None,\n","                                               input_tensor=None,\n","                                               input_shape=(img_height, img_width, 3),\n","                                               pooling='max',\n","                                               classes=11,\n","                                               classifier_activation=\"softmax\")"],"metadata":{"id":"95LuSIVc6vJF"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"11Mqi9Hlclmf"},"outputs":[],"source":["fashion_model = keras.applications.MobileNet(input_shape=(img_height, img_width, 3),\n","                          alpha=1.0,\n","                          depth_multiplier=1,\n","                          dropout=0.001,\n","                          include_top=True,\n","                          weights=None,\n","                          input_tensor=None,\n","                          pooling='max',\n","                          classes=11,\n","                          classifier_activation=\"softmax\")"]},{"cell_type":"code","source":["fashion_model = keras.applications.MobileNetV2(input_shape=(img_height, img_width, 3),\n","                                               alpha=1.0,\n","                                               include_top=True,\n","                                               weights=None,\n","                                               input_tensor=None,\n","                                               pooling='max',\n","                                               classes=11,\n","                                               classifier_activation=\"softmax\")"],"metadata":{"id":"-t48USV2nQRx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fashion_model = keras.applications.MobileNetV3Small(input_shape=(img_height, img_width, 3),\n","                                                    alpha=1.0,\n","                                                    minimalistic=False,\n","                                                    include_top=True,\n","                                                    weights=None,\n","                                                    input_tensor=None,\n","                                                    classes=11,\n","                                                    pooling='max',\n","                                                    dropout_rate=0.2,\n","                                                    classifier_activation=\"softmax\",\n","                                                    include_preprocessing=False)"],"metadata":{"id":"dQcbD5SlwrdD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fashion_model = keras.applications.MobileNetV3Large(input_shape=(img_height, img_width, 3),\n","                                                    alpha=1.0,\n","                                                    minimalistic=False,\n","                                                    include_top=True,\n","                                                    weights=None,\n","                                                    input_tensor=None,\n","                                                    classes=11,\n","                                                    pooling='max',\n","                                                    dropout_rate=0.2,\n","                                                    classifier_activation=\"softmax\",\n","                                                    include_preprocessing=False)"],"metadata":{"id":"1USvqH-D1OFA"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XtKrFqUrdnzt"},"outputs":[],"source":["fashion_model = keras.applications.DenseNet121(include_top=True,\n","                                               weights=None,\n","                                               input_tensor=None,\n","                                               input_shape=(img_height, img_width, 3),\n","                                               pooling='max',\n","                                               classes=11,\n","                                               classifier_activation=\"softmax\")"]},{"cell_type":"code","source":["fashion_model = keras.applications.DenseNet169(include_top=True,\n","                                               weights=None,\n","                                               input_tensor=None,\n","                                               input_shape=(img_height, img_width, 3),\n","                                               pooling='max',\n","                                               classes=11,\n","                                               classifier_activation=\"softmax\")"],"metadata":{"id":"Tf1K18GxBZAx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fashion_model = keras.applications.DenseNet201(include_top=True,\n","                                               weights=None,\n","                                               input_tensor=None,\n","                                               input_shape=(img_height, img_width, 3),\n","                                               pooling='max',\n","                                               classes=11,\n","                                               classifier_activation=\"softmax\")"],"metadata":{"id":"HQzIovx7VNgb"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dHVCJOR9eUHS"},"outputs":[],"source":["fashion_model = keras.applications.NASNetLarge(input_shape=(img_height, img_width, 3),\n","                                               include_top=True,\n","                                               weights=None,\n","                                               input_tensor=None,\n","                                               pooling='max',\n","                                               classes=11,\n","                                               classifier_activation=\"softmax\")"]},{"cell_type":"code","source":["fashion_model = keras.applications.NASNetMobile(input_shape=(img_height, img_width, 3),\n","                                                include_top=True,\n","                                                weights=None,\n","                                                input_tensor=None,\n","                                                pooling='max',\n","                                                classes=11,\n","                                                classifier_activation=\"softmax\")"],"metadata":{"id":"9UfQiT6zttfK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wDGls6vNeoU1"},"outputs":[],"source":["fashion_model = keras.applications.InceptionV3(include_top=True,\n","                                               weights=None,\n","                                               input_tensor=None,\n","                                               input_shape=(img_height, img_width, 3),\n","                                               pooling='max',\n","                                               classes=11,\n","                                               classifier_activation=\"softmax\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5p-myvcbe5Hs"},"outputs":[],"source":["fashion_model = keras.applications.InceptionResNetV2(include_top=True,\n","                                                     weights=None,\n","                                                     input_tensor=None,\n","                                                     input_shape=(img_height, img_width, 3),\n","                                                     pooling='max',\n","                                                     classes=11,\n","                                                     classifier_activation=\"softmax\")"]},{"cell_type":"markdown","source":["## VGGNet"],"metadata":{"id":"JQjJ_LMuCMkB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pe5Bd1QI99bO"},"outputs":[],"source":["def Vgg():\n","  input_img = keras.layers.Input(shape=(img_height, img_width, 3))\n","\n","  conv1 = keras.layers.Conv2D(filters=64, kernel_size=5, padding='same', activation='relu')(input_img)\n","  conv1 = keras.layers.Dropout(0.2)(conv1)\n","  conv1 = keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu')(conv1)\n","  pool1 = keras.layers.MaxPooling2D(2)(conv1)\n","\n","  conv2 = keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu')(pool1)\n","  conv2 = keras.layers.Dropout(0.2)(conv2)\n","  conv2 = keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu')(conv2)\n","  pool2 = keras.layers.MaxPooling2D(2)(conv2)\n","\n","  conv3 = keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(pool2)\n","  conv3 = keras.layers.Dropout(0.2)(conv3)\n","  conv3 = keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(conv3)\n","  pool3 = keras.layers.MaxPooling2D(2)(conv3)\n","\n","  conv4 = keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu')(pool3)\n","  conv4 = keras.layers.Dropout(0.2)(conv4)\n","  conv4 = keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu')(conv4)\n","  pool4 = keras.layers.MaxPooling2D(2)(conv4)\n","\n","  flat = keras.layers.Flatten()(pool4)\n","\n","  dense1 = keras.layers.Dense(1000, activation='relu')(flat)\n","  dense1 = keras.layers.Dropout(0.2)(dense1)\n","\n","  dense2 = keras.layers.Dense(1000, activation='relu')(dense1)\n","  dense2 = keras.layers.Dropout(0.2)(dense2)\n","\n","  dense3 = keras.layers.Dense(1000, activation='relu')(dense2)\n","  dense3 = keras.layers.Dropout(0.2)(dense3)\n","\n","  dense4 = keras.layers.Dense(1000, activation='relu')(dense3)\n","  dense4 = keras.layers.Dropout(0.2)(dense4)\n","\n","  # dense5 = keras.layers.Dense(1000, activation='relu')(dense4)\n","  # dense5 = keras.layers.Dropout(0.4)(dense5)\n","\n","\n","  # 모델이 총 11개의 패션 타입을 분류하므로 마지막 층은 11개의 뉴런 설정\n","  output_label = keras.layers.Dense(11, activation='softmax', name='OutputLayer')(dense4)\n","\n","  model = keras.Model(input_img, output_label)\n","  return model"]},{"cell_type":"markdown","source":["## GoogLeNet"],"metadata":{"id":"qGZgfReVCi6l"}},{"cell_type":"code","source":["def Inception_block(input_layer, f1, f2_conv1, f2_conv3, f3_conv1, f3_conv5, f4):\n","  # Input:\n","  # - f1: number of filters of the 1x1 convolutional layer in the first path\n","  # - f2_conv1, f2_conv3 are number of filters corresponding to the 1x1 and 3x3 convolutional layers in the second path\n","  # - f3_conv1, f3_conv5 are the number of filters corresponding to the 1x1 and 5x5  convolutional layer in the third path\n","  # - f4: number of filters of the 1x1 convolutional layer in the fourth path\n","\n","  # 1st path:\n","  path1 = keras.layers.Conv2D(filters=f1, kernel_size = 1, padding = 'same', activation = 'relu')(input_layer)\n","\n","  # 2nd path\n","  path2 = keras.layers.Conv2D(filters = f2_conv1, kernel_size = 1, padding = 'same', activation = 'relu')(input_layer)\n","  path2 = keras.layers.Conv2D(filters = f2_conv3, kernel_size = 3, padding = 'same', activation = 'relu')(path2)\n","\n","  # 3rd path\n","  path3 = keras.layers.Conv2D(filters = f3_conv1, kernel_size = 1, padding = 'same', activation = 'relu')(input_layer)\n","  path3 = keras.layers.Conv2D(filters = f3_conv5, kernel_size = 5, padding = 'same', activation = 'relu')(path3)\n","\n","  # 4th path\n","  path4 = keras.layers.MaxPooling2D(3, strides= 1, padding = 'same')(input_layer)\n","  path4 = keras.layers.Conv2D(filters = f4, kernel_size = 1, padding = 'same', activation = 'relu')(path4)\n","\n","  output_layer = keras.layers.concatenate([path1, path2, path3, path4], axis = -1)\n","\n","  return output_layer"],"metadata":{"id":"jbA5yudfdOri"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def GoogLeNet():\n","  # input layer\n","  input_layer = keras.layers.Input(shape = (img_height, img_width, 3))\n","\n","  # Inception layers\n","  X = keras.layers.Conv2D(filters = 64, kernel_size = 7, strides = 2, padding = 'valid', activation = 'relu')(input_layer)\n","  # X = keras.layers.MaxPooling2D(pool_size = 3, strides = 2)(X)\n","  X = keras.layers.Conv2D(filters = 64, kernel_size = 1, strides = 1, padding = 'same', activation = 'relu')(X)\n","  X = keras.layers.Conv2D(filters = 192, kernel_size = 3, padding = 'same', activation = 'relu')(X)\n","  X = keras.layers.MaxPooling2D(pool_size= 3, strides = 2)(X)\n","  # dropout 추가\n","  # X = keras.layers.Dropout(0.3)(X)\n","\n","  X = Inception_block(X, f1 = 64, f2_conv1 = 96, f2_conv3 = 128, f3_conv1 = 16, f3_conv5 = 32, f4 = 32)\n","  X = Inception_block(X, f1 = 128, f2_conv1 = 128, f2_conv3 = 192, f3_conv1 = 32, f3_conv5 = 96, f4 = 64)\n","  X = keras.layers.MaxPooling2D(pool_size= 3, strides = 2)(X)\n","  # dropout 추가\n","  # X = keras.layers.Dropout(0.3)(X)\n","\n","  X = Inception_block(X, f1 = 192, f2_conv1 = 96, f2_conv3 = 208, f3_conv1 = 16, f3_conv5 = 48, f4 = 64)\n","  X = Inception_block(X, f1 = 160, f2_conv1 = 112, f2_conv3 = 224, f3_conv1 = 24, f3_conv5 = 64, f4 = 64)\n","  X = Inception_block(X, f1 = 128, f2_conv1 = 128, f2_conv3 = 256, f3_conv1 = 24, f3_conv5 = 64, f4 = 64)\n","  X = Inception_block(X, f1 = 112, f2_conv1 = 144, f2_conv3 = 288, f3_conv1 = 32, f3_conv5 = 64, f4 = 64)\n","  X = Inception_block(X, f1 = 256, f2_conv1 = 160, f2_conv3 = 320, f3_conv1 = 32, f3_conv5 = 128, f4 = 128)\n","  X = keras.layers.MaxPooling2D(pool_size = 3, strides = 2)(X)\n","  # dropout 추가\n","  # X = keras.layers.Dropout(0.3)(X)\n","\n","  X = Inception_block(X, f1 = 256, f2_conv1 = 160, f2_conv3 = 320, f3_conv1 = 32, f3_conv5 = 128, f4 = 128)\n","  X = Inception_block(X, f1 = 384, f2_conv1 = 192, f2_conv3 = 384, f3_conv1 = 48, f3_conv5 = 128, f4 = 128)\n","\n","  # Global Average pooling layer\n","  X = keras.layers.GlobalAveragePooling2D(name = 'GAPL')(X)\n","\n","  # Dropoutlayer\n","  X = keras.layers.Dropout(0.4)(X)\n","\n","  # Dense layer. 쓸모 있을지는 모르겠다\n","  X = keras.layers.Dense(1000, activation='relu')(X)\n","  X = keras.layers.Dropout(0.2)(X)\n","  X = keras.layers.Dense(1000, activation='relu')(X)\n","\n","  # output layer\n","  # 모델이 총 11개의 패션 타입을 분류하므로 마지막 층은 10개의 뉴런 설정\n","  output_layer = keras.layers.Dense(11, activation='softmax', name='OutputLayer')(X)\n","\n","  # model 정의\n","  model = keras.Model(input_layer, output_layer, name = 'GoogLeNet')\n","\n","  return model"],"metadata":{"id":"qB-qQ183-uVv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fashion_model = Vgg()\n","# fashion_model = GoogLeNet()"],"metadata":{"id":"VgDLBSkCf5Aq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# adam learning_rate 기본값 0.001\n","adam = keras.optimizers.Adam(learning_rate=0.00002)\n","fashion_model.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=[keras.metrics.SparseCategoricalAccuracy()])"],"metadata":{"id":"lv0c4Gv1G06E"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2U1F0ac4-CLg"},"outputs":[],"source":["fashion_model.summary()"]},{"cell_type":"markdown","metadata":{"id":"rdCMwvR0qX2K"},"source":["## 모델이 덮어쓰기되지 않도록 이름 잊지말고 바꿔주기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mqbx01_eqgTl"},"outputs":[],"source":["fashion_model_path = model_dir_name + 'fashion_classification_female_0809_03.keras'"]},{"cell_type":"code","source":["# 기존 저장된 모델을 불러올 경우\n","fashion_model = keras.models.load_model(fashion_model_path)\n","fashion_model.summary()"],"metadata":{"id":"DJn9awbSj7m9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lgKoi6gBETxi"},"source":["# 모델 학습"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jO9p0u2rEVUZ"},"outputs":[],"source":["checkpoint_cb = keras.callbacks.ModelCheckpoint(fashion_model_path, save_best_only=True)\n","early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vV0oq7uTEW_I"},"outputs":[],"source":["history = fashion_model.fit(x_train, y_train,\n","                            epochs=50, verbose=1,\n","                            validation_data=(x_val, y_val),\n","                            callbacks=[checkpoint_cb, early_stopping_cb])\n","\n","print()\n","print(\"Complete\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fCnUz2A0EgOz"},"outputs":[],"source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.legend(['train', 'val'])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"CEGERcBJEis0"},"source":["# 모델 테스트"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LpEoltUHWfED"},"outputs":[],"source":["saved_model_path = model_dir_name + 'fashion_classification_female_0809_03.keras'\n","\n","saved_model = keras.models.load_model(saved_model_path)"]},{"cell_type":"code","source":["saved_model.summary()"],"metadata":{"id":"xQQ3U5hPctWc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RPaGILOCWc0U"},"source":["## 1개 Test 데이터 예측결과 확인"]},{"cell_type":"code","source":["y_test.shape"],"metadata":{"id":"eBdAIBytcZLB"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yHPN1ZYNWXpP"},"outputs":[],"source":["num = random.randint(0, 4900)\n","print(\"Random Number : \", num)\n","\n","preds = saved_model.predict(x_test[num:num+1])\n","type(preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hA_mW6hFEk3s"},"outputs":[],"source":["true_label = label_name[y_test[num]]\n","pred_label = label_name[np.argmax(preds)]\n","\n","plt.imshow(x_test[num])\n","plt.show()\n","\n","print('True Label : ', true_label)\n","print('Pred Label : ', pred_label)"]},{"cell_type":"markdown","metadata":{"id":"6APUy9c7WiTV"},"source":["## 전체 Test 데이터 정확도 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mYrATClvExkM"},"outputs":[],"source":[" saved_model.evaluate(x_test, y_test)"]}]}